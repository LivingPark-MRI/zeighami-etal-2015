{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notbook I am trying to reproduce Zeighami *et al*, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing link inputs\n",
      "removing link outputs\n",
      "Installing notebook dependencies (see log in install.log)... \n",
      "This notebook was run on 2022-11-03 17:49:44 UTC +0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show = true;\n",
       "    function code_toggle() {\n",
       "        if (code_show) {\n",
       "            $(\"div.input\").hide();\n",
       "        } else {\n",
       "            $(\"div.input\").show();\n",
       "        }\n",
       "        code_show = !code_show\n",
       "    }\n",
       "    $(document).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\">\n",
       "    <input type=\"submit\" value=\"Click here to toggle on/off the Python code.\">\n",
       "</form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import livingpark_utils\n",
    "\n",
    "utils = livingpark_utils.LivingParkUtils()\n",
    "utils.notebook_init()\n",
    "# utils.download_ppmi_metadata([\"Demographics.csv\",\n",
    "#                             \"Primary_Clinical_Diagnosis.csv\",\n",
    "#                             \"Cognitive_Categorization.csv\",\n",
    "#                             \"Medical_Conditions_Log.csv\",\n",
    "#                             \"Concomitant_Medication_Log.csv\",\n",
    "#                             \"MDS-UPDRS Part III ON/OFF Determination & Dosing\",\n",
    "#                             \"MDS UPDRS Part III\",\n",
    "#                             \"Montreal Cognitive Assessment (MoCA)\"],headless=False)\n",
    "# utils.find_nifti_file_in_cache(x[\"PATNO\"], x[\"EVENT_ID\"], x[\"Description\"])\n",
    "# utils.disease_duration()\n",
    "# utils.moca2mmse(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livingpark_utils.zeighamietal.constants import (\n",
    "    FILENAME_PARTICIPANT_STATUS,\n",
    "    FILENAME_DEMOGRAPHICS,\n",
    "    FILENAME_AGE,\n",
    "    FILENAME_MOCA,\n",
    "    FILENAME_UPDRS3,\n",
    "    FILENAME_T1_INFO,\n",
    ")\n",
    "\n",
    "from livingpark_utils.zeighamietal.constants import (\n",
    "    COL_PAT_ID,\n",
    "    COL_STATUS,\n",
    "    COL_VISIT_TYPE,\n",
    "    COL_DATE_INFO,\n",
    ")\n",
    "\n",
    "from livingpark_utils.zeighamietal.constants import (\n",
    "    STATUS_PD,\n",
    "    STATUS_HC,\n",
    "    MAIN_COHORT,\n",
    "    VISIT_BASELINE,\n",
    "    VISIT_SCREENING,\n",
    "    SEX_FEMALE,\n",
    "    SEX_MALE,\n",
    "    MAX_DATES,\n",
    ")\n",
    "\n",
    "from livingpark_utils.zeighamietal.constants import (\n",
    "    COL_PD_STATE,\n",
    "    COL_AGE,\n",
    "    COL_SEX,\n",
    "    COL_EDUCATION,\n",
    "    COL_MOCA,\n",
    "    COL_PIGD,\n",
    "    COL_GCO,\n",
    "    COLS_PIGD_COMPONENTS_UPDRS3,\n",
    "    COLS_PIGD_COMPONENTS,\n",
    "    COLS_SCORES,\n",
    "    COLS_SCORES_WITHOUT_GCO,\n",
    "    COL_FOLLOWUP,\n",
    ")\n",
    "\n",
    "from livingpark_utils.zeighamietal import (\n",
    "    load_ppmi_csv,\n",
    "    get_t1_cohort,\n",
    "    mean_impute,\n",
    "    filter_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_UPDRS3 = [\"NHY\", \"NP3TOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livingpark_utils.scripts import run\n",
    "\n",
    "# run.mri_metadata()\n",
    "# run.pd_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILENAME_DEMOGRAPHICS = \"Demographics.csv\"\n",
    "FILENAME_AGE = \"Age_at_visit.csv\"\n",
    "FILENAME_PARTICIPANT_STATUS = \"Participant_Status.csv\"\n",
    "FILENAME_MOCA = \"Montreal_Cognitive_Assessment__MoCA_.csv\"\n",
    "FILENAME_UPDRS3 = \"MDS_UPDRS_Part_III.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Main cohort ===============\n",
      "Removing extra scans for 1 subjects\n",
      "Parkinson's Disease    236\n",
      "Healthy Control        113\n",
      "Name: COHORT_DEFINITION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_status = load_ppmi_csv(utils, FILENAME_PARTICIPANT_STATUS)\n",
    "\n",
    "cohort_t1_map = {}\n",
    "cohort_name = MAIN_COHORT\n",
    "\n",
    "print(f\"=============== {cohort_name.capitalize()} cohort ===============\")\n",
    "\n",
    "df_t1_subset = get_t1_cohort(\n",
    "    utils,\n",
    "    cohort_name=cohort_name,\n",
    "    filename=FILENAME_T1_INFO,\n",
    "    sagittal_only=True,\n",
    ")\n",
    "cohort_t1_map[cohort_name] = df_t1_subset\n",
    "\n",
    "# cohort composition: number of PD patients/healthy controls\n",
    "print(\n",
    "    df_status.loc[\n",
    "        df_status[COL_PAT_ID].isin(df_t1_subset[COL_PAT_ID]), COL_STATUS\n",
    "    ].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_merge = [COL_PAT_ID, COL_DATE_INFO, COL_VISIT_TYPE]\n",
    "df_updrs3 = load_ppmi_csv(\n",
    "    utils, FILENAME_UPDRS3, cols_to_impute=COLS_PIGD_COMPONENTS_UPDRS3 + COL_UPDRS3\n",
    ")\n",
    "df_moca = load_ppmi_csv(utils, FILENAME_MOCA)  # do not impute\n",
    "df_updrs3 = df_updrs3.loc[df_updrs3[COL_PD_STATE] != \"OFF\"]\n",
    "\n",
    "df_updrs3 = df_updrs3.loc[:, cols_for_merge + COL_UPDRS3]\n",
    "df_moca = df_moca.loc[:, cols_for_merge + [COL_MOCA]]\n",
    "\n",
    "df_assessments_all = reduce(\n",
    "    lambda df1, df2: df1.merge(df2, on=cols_for_merge, how=\"outer\"),\n",
    "    [ df_updrs3, df_moca],\n",
    ").drop_duplicates()\n",
    "\n",
    "# some missing values remain even if we use the screening visit score\n",
    "# we will impute these using the original mean\n",
    "mean_moca = df_moca[COL_MOCA].mean()\n",
    "\n",
    "cols_to_impute = [col for col in [\"NHY\", \"NP3TOT\", \"MCATOT\"] if col != COL_MOCA]\n",
    "df_assessments_all = mean_impute(df_assessments_all, cols_to_impute)\n",
    "\n",
    "# keep only subjects who have a T1\n",
    "cohort_assessments_map_orig = {}\n",
    "for cohort_name, df_t1_subset in cohort_t1_map.items():\n",
    "    cohort_assessments_map_orig[cohort_name] = df_assessments_all.loc[\n",
    "        df_assessments_all[COL_PAT_ID].isin(df_t1_subset[COL_PAT_ID])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16130 entries, 0 to 19365\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   PATNO     16130 non-null  int64         \n",
      " 1   INFODT    16130 non-null  datetime64[ns]\n",
      " 2   EVENT_ID  16130 non-null  object        \n",
      " 3   NHY       16130 non-null  float64       \n",
      " 4   NP3TOT    16130 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(1)\n",
      "memory usage: 756.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_updrs3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MAIN COHORT ==========\n",
      "Parkinson's Disease    236\n",
      "Healthy Control        113\n",
      "Name: COHORT_DEFINITION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_date_diff = \"date_diff\"\n",
    "\n",
    "cohort_assessments_map = {}\n",
    "for cohort_name in cohort_assessments_map_orig:\n",
    "\n",
    "    print(f\"========== {cohort_name.upper()} COHORT ==========\")\n",
    "\n",
    "    date_diffs = []\n",
    "\n",
    "    df_assessments_cohort: pd.DataFrame = cohort_assessments_map_orig[cohort_name]\n",
    "    df_assessments_baseline = df_assessments_cohort.loc[\n",
    "        df_assessments_cohort[COL_VISIT_TYPE] == VISIT_BASELINE\n",
    "    ]\n",
    "    df_assessments_screening = df_assessments_cohort.loc[\n",
    "        df_assessments_cohort[COL_VISIT_TYPE] == VISIT_SCREENING\n",
    "    ]\n",
    "\n",
    "    # try to fill in missing baseline data\n",
    "    for idx_row_baseline, row_baseline in df_assessments_baseline.iterrows():\n",
    "\n",
    "        subject = row_baseline[COL_PAT_ID]\n",
    "        date_baseline = row_baseline[COL_DATE_INFO]\n",
    "\n",
    "        # for each score columns\n",
    "        for col in [COL_MOCA]:\n",
    "         \n",
    "            # fill missing values with screening data\n",
    "            if pd.isna(row_baseline[col]):\n",
    "\n",
    "                df_screening_subject = df_assessments_screening.loc[\n",
    "                    df_assessments_screening[COL_PAT_ID] == subject\n",
    "                ]\n",
    "\n",
    "                # some subjects in validation set had multiple screening visits\n",
    "                # in this case we sort them by how close they are to the baseline visit\n",
    "                n_screening = len(df_screening_subject)\n",
    "                if n_screening > 1:\n",
    "                    df_screening_subject[col_date_diff] = (\n",
    "                        date_baseline - df_screening_subject[COL_DATE_INFO]\n",
    "                    )\n",
    "                    df_screening_subject = df_screening_subject.sort_values(\n",
    "                        col_date_diff, ascending=True\n",
    "                    )\n",
    "\n",
    "                # find corresponding assessment score in screening visits\n",
    "                for idx_row_screening, row_screening in df_screening_subject.iterrows():\n",
    "                    new_value = row_screening[col]\n",
    "                    date_diff = date_baseline - row_screening[COL_DATE_INFO]\n",
    "                    if not pd.isna(new_value):\n",
    "                        break\n",
    "\n",
    "                # replace\n",
    "                if not pd.isna(new_value):\n",
    "                    df_assessments_baseline.loc[idx_row_baseline, col] = new_value\n",
    "                    date_diffs.append(date_diff.days)  # for plotting\n",
    "                    \n",
    "    subjects_common = set(df_assessments_cohort[COL_PAT_ID])\n",
    "    # print cohort composition\n",
    "    print(\n",
    "        df_status.loc[\n",
    "            df_status[COL_PAT_ID].isin(subjects_common), COL_STATUS\n",
    "        ].value_counts()\n",
    "    )\n",
    "    \n",
    "    df_assessments_baseline[COL_FOLLOWUP] = False\n",
    "\n",
    "    # impute remaining missing MoCA values\n",
    "    df_assessments_baseline.loc[\n",
    "        df_assessments_baseline[COL_MOCA].isna(), COL_MOCA\n",
    "    ] = mean_moca\n",
    "\n",
    "    cohort_assessments_map[cohort_name] = df_assessments_baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort_name, df_assessments in cohort_assessments_map.items():\n",
    "    df = df_assessments[['NP3TOT', 'MCATOT','NHY']].copy()\n",
    "    gco_means = df.mean()\n",
    "    gco_stds = df.std()\n",
    "    gco = ((df - gco_means) / gco_stds).mean(\n",
    "        axis=\"columns\"\n",
    "    )\n",
    "    cohort_assessments_map[cohort_name][COL_GCO] = gco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GCO_calculator(cohort_assessments_map, cols) ->:\n",
    "#     df = df_assessments[cols].copy()\n",
    "#     gco_means = df.mean()\n",
    "#     gco_stds = df.std()\n",
    "#     gco = ((df - gco_means) / gco_stds).mean(\n",
    "#         axis=\"columns\"\n",
    "#     )\n",
    "#     cohort_assessments_map[cohort_name][COL_GCO] = gco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COHORT_DEFINITION</th>\n",
       "      <th>Healthy Control</th>\n",
       "      <th>Parkinson's Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>60.1 (11.3)</td>\n",
       "      <td>61.2 (9.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male (%)</th>\n",
       "      <td>62.8</td>\n",
       "      <td>60.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPDRS Part III</th>\n",
       "      <td>1.2 (2.7)</td>\n",
       "      <td>21.5 (8.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H &amp; Y</th>\n",
       "      <td>0.0 (0.1)</td>\n",
       "      <td>1.6 (0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoCA</th>\n",
       "      <td>28.3 (1.2)</td>\n",
       "      <td>27.4 (2.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global composite outcome</th>\n",
       "      <td>-0.7 (0.2)</td>\n",
       "      <td>0.3 (0.5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COHORT_DEFINITION        Healthy Control Parkinson's Disease\n",
       "Age                          60.1 (11.3)          61.2 (9.3)\n",
       "Male (%)                            62.8                60.9\n",
       "UPDRS Part III                 1.2 (2.7)          21.5 (8.9)\n",
       "H & Y                          0.0 (0.1)           1.6 (0.5)\n",
       "MoCA                          28.3 (1.2)          27.4 (2.2)\n",
       "Global composite outcome      -0.7 (0.2)           0.3 (0.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_1_decimal_str(f):\n",
    "    return str(round(f, 1))\n",
    "\n",
    "\n",
    "df_age = load_ppmi_csv(utils, FILENAME_AGE)\n",
    "df_demographics = load_ppmi_csv(utils, FILENAME_DEMOGRAPHICS)\n",
    "\n",
    "col_male = \"is_male\"\n",
    "col_cohort = \"cohort\"\n",
    "\n",
    "dfs_summary = []\n",
    "df_assessments: pd.DataFrame\n",
    "for cohort_name, df_assessments in cohort_assessments_map.items():\n",
    "\n",
    "    subjects = df_assessments[COL_PAT_ID].drop_duplicates()\n",
    "\n",
    "    # general demographics (baseline session only)\n",
    "    df_assessments =df_assessments.merge(df_status,on=[COL_PAT_ID],how=\"outer\")\n",
    "    df_summary = df_assessments.merge(df_age, on=[COL_PAT_ID, COL_VISIT_TYPE],how=\"outer\")\n",
    "    df_demographics[col_male] = (df_demographics[COL_SEX] == SEX_MALE).apply(\n",
    "        lambda v: 100 if v else 0\n",
    "    )\n",
    "\n",
    "   \n",
    "    df_summary = df_summary.merge(df_demographics, on=COL_PAT_ID,how=\"outer\")\n",
    "    df_summary = df_summary[[COL_PAT_ID, COL_AGE, col_male, COL_STATUS, COL_UPDRS3[1],COL_UPDRS3[0],COL_MOCA, COL_GCO]]\n",
    "\n",
    "    # append\n",
    "    df_summary[col_cohort] = cohort_name\n",
    "    dfs_summary.append(df_summary)\n",
    "\n",
    "df_summary = pd.concat(dfs_summary)\n",
    "df_summary = df_summary.iloc[np.where(df_summary[COL_STATUS].isin([STATUS_PD,STATUS_HC]))]\n",
    "df_summary = df_summary.drop(columns=COL_PAT_ID)\n",
    "df_summary_means = (\n",
    "    df_summary.groupby([COL_STATUS]).mean().applymap(to_1_decimal_str))\n",
    "\n",
    "df_summary_stds = (\n",
    "    df_summary.groupby([COL_STATUS]).std().applymap(to_1_decimal_str)\n",
    ")\n",
    "df_summary_stds = \" (\" + df_summary_stds + \")\"\n",
    "df_summary_stds.loc[:, col_male] = \"\"\n",
    "df_summary_combined = (df_summary_means + df_summary_stds).T\n",
    "df_summary_combined = df_summary_combined.applymap(lambda x: \"-\" if \"nan\" in x else x)\n",
    "df_summary_combined = df_summary_combined.rename(\n",
    "    index={\n",
    "        COL_AGE: \"Age\",\n",
    "        col_male: \"Male (%)\",\n",
    "        COL_UPDRS3[1]: \"UPDRS Part III\",\n",
    "        COL_UPDRS3[0]: \"H & Y\",\n",
    "        COL_MOCA: \"MoCA\",\n",
    "        COL_GCO: \"Global composite outcome\",\n",
    "    }\n",
    ")\n",
    "df_summary_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_summary.iloc[np.where(df_summary[COL_STATUS] == STATUS_HC)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[np.where((~df[COL_UPDRS3[1]].isna()) & (df[COL_UPDRS3[1]] >=0.1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[np.where((~df[COL_UPDRS3[1]].isna()) & (df[COL_UPDRS3[1]] >=0.1))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34ac72a99a8d161ddae0a97484965b163e14fc1004e96fbe7e082180324cacb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
